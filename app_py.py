# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cQc1YWv3R2DJG45ZTDVnYB-YJepdMo0Q
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import torch
# from transformers import AutoTokenizer, AutoModelForSequenceClassification
# import torch.nn.functional as F
# 
# # Page config
# st.set_page_config(page_title="Sentiment Analysis Demo", page_icon="üé¨")
# 
# # Device
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# 
# @st.cache_resource
# def load_model():
#     tokenizer = AutoTokenizer.from_pretrained("sentiment-model")
#     model = AutoModelForSequenceClassification.from_pretrained("sentiment-model")
#     model.to(device)
#     model.eval()
#     return tokenizer, model
# 
# tokenizer, model = load_model()
# 
# st.title("üé¨ Movie Review Sentiment Analysis")
# st.write("Type a movie review and the model will predict **Positive** or **Negative** sentiment.")
# 
# text = st.text_area(
#     "‚úèÔ∏è Enter a review:",
#     "This movie was absolutely fantastic, I loved it!",
#     height=150
# )
# 
# if st.button("Analyze sentiment"):
#     inputs = tokenizer(
#         text,
#         return_tensors="pt",
#         truncation=True,
#         padding=True,
#         max_length=256
#     )
#     inputs = {k: v.to(device) for k, v in inputs.items()}
# 
#     with torch.no_grad():
#         outputs = model(**inputs)
#         probs = F.softmax(outputs.logits, dim=-1)
# 
#     pred = torch.argmax(probs, dim=-1).item()
#     confidence = probs[0][pred].item()
# 
#     if pred == 1:
#         st.success(f"‚úÖ Positive sentiment ({confidence:.2f})")
#     else:
#         st.error(f"‚ùå Negative sentiment ({confidence:.2f})")
#